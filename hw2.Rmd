---
title: "Financial Time Series Analysis HW 02"
author: "Varshini Yanamandra"
date: "2023-02-20"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dlm)
library(astsa)
library(tseries)
library(fBasics)
library(stats)
```

Question 1

```{r}
lt.data <- scan('lt.txt') # reading the data into a vector of length 500
```

Part (d)

```{r}
# MLE estimation
para.start = c(1, 1) # defining the starting values for V and W
lt <- function(x) {
  dlm(FF = 1, V = x[1], GG = 1, W = x[2], m0 = 0.2, C0 = 2.25) # V is sigma2_e and W is sigma2_eta; s_0 ~ N(0.2, 2.25)
}

m.lt <- dlmMLE(y = lt.data, parm = para.start, build = lt, lower = c(0, 0), upper = c(100, 100), hessian = T, control = list(maxit = 100))
m.lt
```

```{r}
buildlt = lt(m.lt$par)
V(buildlt) # value of the MLE estimate for sigma2_e
```

```{r}
W(buildlt) # value of the MLE estimate for sigma2_eta
```

We can get the standard errors of the MLE estimates by solving the inverse of the Hessian matrix.

```{r}
# standard errors of the MLE estimates
sqrt(diag(solve(m.lt$hessian)))
```


Part (e)

```{r}
# reproducing plot in part (b) - predicted state variables s_t|(t - 1)
s.filter <- dlmFilter(lt.data, lt(m.lt$par))
N = length(lt.data)

plot(s.filter$a, type = 'l', main = "Prediction", ylim = c(-0.2, 3)) # plotting the predicted state variables

s.pv <- rep(0, N)
for (t in 1:N) {
  s.pv[t] = s.filter$U.R[[t]] %*% diag(s.filter$D.R[t, ]^2, nrow = 1) %*% t(s.filter$U.R[[t]])
}
# plotting the 95% confidence intervals
lines(s.filter$a + qnorm(0.975) * sqrt(s.pv), lty = 3, col = "blue")
lines(s.filter$a - qnorm(0.975) * sqrt(s.pv), lty = 3, col = "blue")
```

```{r}
# reproducing plot in part (c) - filtered state variables s_t|t
plot(s.filter$m[-1], type = 'l', main = "Filtering", ylim = c(-0.2, 3)) # plotting the filtered state variables

s.fv <- rep(0, N)
for (t in 2:(N + 1)) {
  s.fv[t - 1] = s.filter$U.C[[t]] %*% diag(s.filter$D.C[t, ]^2, nrow = 1 %*% t(s.filter$U.C[[t]]))
}
# plotting the 95% confidence intervals
lines(s.filter$m[-1] + qnorm(0.975) * sqrt(s.fv), lty = 3, col = "blue")
lines(s.filter$m[-1] - qnorm(0.975) * sqrt(s.fv), lty = 3, col = "blue")
```

```{r}
# plotting the smoothed state variable s_t|T
s.smooth <- dlmSmooth(lt.data, lt(m.lt$par))

plot(s.smooth$s[-1], type = 'l', ylim = c(-0.2, 3), main = "Smoothing") # plotting the smoothed state variables

s.sv = rep(0, N)
for (t in 2:(N + 1)) {
    s.sv[t - 1] = s.smooth$U.S[[t]] %*% diag(s.smooth$D.S[t, ]^2, nrow = 1) %*% t(s.smooth$U.S[[t]])
}
# plotting the 95% confidence intervals
lines(s.smooth$s[-1] + qnorm(0.975) * sqrt(s.sv), lty = 3, col = "blue")
lines(s.smooth$s[-1] - qnorm(0.975) * sqrt(s.sv), lty = 3, col = "blue")
```

Part (f)

```{r}
# using StructTS to find the MLE estimates
lt.struct <- StructTS(lt.data, type = "level")

sigma2_eta = lt.struct$coef[[1]]
sigma2_e = lt.struct$coef[[2]]

sigma2_e # same as V in part (d) - very close in value
sigma2_eta # same as W in part (d) - very close in value
```


Question 3

Part (a)

```{r}
t = 600 # length of the time-series we need to generate

# sd = 2 in all of the simulations below since a_t ~ N(0, 4) = N(0, 2^2)

# ts (i) - AR(3)
x1 <- arima.sim(model = list(ar = c(0.8, -0.5, -0.2)), n = t, mean = 0, sd = 2) + 0.3

# time-series plot
plot(x1, main = paste("AR(3), phi_1 = 0.8, phi_2 = -0.5, phi_3 = -0.2, c = 0.3"), xlab = "time", ylab = "value")
```

```{r}
# ts (ii) - MA(3)
x2 <- arima.sim(model = list(ma = c(-0.8, 0.5, 0.2)), n = t, mean = 0, sd = 2) + 0.3

# time-series plot
plot(x2, main = paste("MA(3), theta_1 = 0.8, theta_2 = -0.5, theta_3 = -0.2, c = 0.3"), xlab = "time", ylab = "value")
```

```{r}
# ts (iii) - ARMA(3, 2)
x3 <- arima.sim(model = list(ar = c(0.8, -0.5, -0.2), ma = c(-0.5, -0.3)), n = t, mean = 0, sd = 2) + 0.3

# time-series plot
plot(x2, main = paste("ARMA(3,2), phi_1 = 0.8, phi_2 = -0.5, phi_3 = -0.2,\n theta_1 = 0.5, theta_2 = 0.3, c = 0.3"), xlab = "time", ylab = "value")
```

Part (b)

```{r}
# memory function definition
## doing this instead of mentioning the source R file, which is an alternative method
memory=function(ar=0, ma=0, lag){
    p=length(ar)
    q=length(ma)
    theta=rep(0,lag+1)
    theta[1]=1
    theta[2:(q+1)]=ma
    phi=rep(0,lag+1)
    phi[1]=1
    phi[2:(p+1)]=ar
    psi=rep(0,lag+1)
    psi[1]=1

    for (k in 1:lag){
        psi[1+k] = sum(phi[1+1:k]*psi[k:1]) + theta[1+k]
    }
    
    return(psi)
}
```

```{r}
# ts (i) - AR(3)
rr1 = memory(ar = c(0.8, -0.5, -0.2), lag = 10)

plot(0:10, rr1, type = "h", xlab = "lag", ylab = "memory function")
title("Memory Function:\n AR(3), phi_1 = 0.8, phi_2 = -0.5, phi_3 = -0.2, c = 0.3, lag = 10")
abline(h = 0)
```

```{r}
# ts (ii) - MA(3)
rr2 = memory(ma = c(-0.8, 0.5, 0.2), lag = 10)

plot(0:10, rr2, type = "h", xlab = "lag", ylab = "memory function")
title("Memory Function:\n MA(3), theta_1 = 0.8, theta_2 = -0.5, theta_3 = -0.2, c = 0.3, lag = 10")
abline(h = 0)
```

```{r}
# ts (iii) - ARMA(3, 2)
rr3 = memory(ar = c(0.8, -0.5, -0.2), ma = c(-0.5, -0.3), lag = 10)

plot(0:10, rr3, type = "h", xlab = "lag", ylab = "memory function")
par(cex.main = 0.8)
title("Memory Function:\n ARMA(3,2), phi_1 = 0.8, phi_2 = -0.5, phi_3 = -0.2,\n theta_1 = 0.5, theta_2 = 0.3, c = 0.3, lag = 10")
abline(h = 0)
```

Part (c)

```{r}
# auto.cov function definition
auto.cov=function(ar=0,ma=0,sigma2=1,lag){
    p=length(ar)
    q=length(ma)
    m=max(p,q)+1
    Phi=array(0,c(m,m))
    phi=rep(0,m)
    phi[1]=1
    phi[1:p+1]=-ar
    theta=rep(0,m)
    theta[1]=1
    theta[1:q+1]=ma
    psi=memory(ar,ma,lag)
    b=rep(0,m)

    Phi[1,]=phi
    for (i in 2:m){
        Phi[i,1:(m-i+1)] = phi[i:m]
        Phi[i,2:i] = Phi[i,2:i] + phi[(i-1):1]
    }
    for (i in 1:m){
        b[i]=sum(psi[1:(m-i+1)]*theta[i:m])
    }

    gamma=rep(0,lag+1)
    gamma[1:m]=solve(Phi)%*%b
    for (k in m:lag){
        gamma[k+1] = sum(ar*gamma[k:(k-p+1)])
    }
    return(gamma*sigma2)
}
```

```{r}
# ts (i) - AR(3)
ac1 = auto.cov(ar = c(0.8, -0.5, -0.2), sigma2 = 4, lag = 10)
ac1 = ac1/ac1[1]

plot(0:10, ac1, type = "h", xlab = "lag", ylab = "ACF")
title("ACF:\n AR(3), phi_1 = 0.8, phi_2 = -0.5, phi_3 = -0.2, c = 0.3, lag = 10")
abline(h = 0)
```

```{r}
# ts (ii) - MA(3)
ac2 = auto.cov(ma = c(-0.8, 0.5, 0.2), sigma2 = 4, lag = 10)
ac2 = ac2/ac2[1]

plot(0:10, ac2, type = "h", xlab = "lag", ylab = "ACF")
title("ACF:\n MA(3), theta_1 = 0.8, theta_2 = -0.5, theta_3 = -0.2, c = 0.3, lag = 10")
abline(h = 0)
```

```{r}
# ts (iii) - ARMA(3, 2)
ac3 = auto.cov(ar = c(0.8, -0.5, -0.2), ma = c(-0.5, -0.3), sigma2 = 4, lag = 10)
ac3 = ac3/ac3[1]

plot(0:10, ac3, type = "h", xlab = "lag", ylab = "ACF")
par(cex.main = 0.8)
title("ACF:\n ARMA(3,2), phi_1 = 0.8, phi_2 = -0.5, phi_3 = -0.2,\n theta_1 = 0.5, theta_2 = 0.3, c = 0.3, lag = 10")
abline(h = 0)
```

Part (d)

The theoretical ACFs are calculated using the auto.cov() function (done in part (c)), and the sample autocorrelations are calculated using the acf() function.

```{r}
# plotting the ACF until lag 10 for the three time-series

# ts (i) - AR(3)
par(mfrow = c(1, 2))
plot(0:10, ac1, type = "h", xlab = "Lag", ylab = "ACF", main = "Theoretical ACFs")
abline(h = 0)
acf(x1, lag.max = 10, main = "")
title("Sample ACFs", line = 1)
```

We can see that the sample ACFs match the theoretical ACFs to a very good degree. They follow the same trend and also have similar values (very close to each other.)

```{r}
# ts (ii) - MA(3)
par(mfrow = c(1, 2))
plot(0:10, ac2, type = "h", xlab = "Lag", ylab = "ACF", main = "Theoretical ACFs")
abline(h = 0)
acf(x2, lag.max = 10, main = "")
title("Sample ACFs", line = 1)
```

Theoretically, we expect the ACFs to vanish after lag 3, since the process is an MA(3) process. We can see that, while not exactly 0, the ACFs after lag = 3 become very close to 0. This can be explained by the smaller sample size of 600, which is not very close to the size of the population. 
However, we can say that the trend is followed closely, though not perfectly.

```{r}
# ts (iii) - ARMA(3, 2)
par(mfrow = c(1, 2))
plot(0:10, ac3, type = "h", xlab = "Lag", ylab = "ACF", main = "Theoretical ACFs")
abline(h = 0)
acf(x3, lag.max = 10, main = "")
title("Sample ACFs", line = 1)
```

Here, we can see that the sample ACFs are in agreement with the theoretical ACFs for the most part. The small variations can again be explained by the relatively small sample size.
The sample ACFs are mostly in agreement with the theoretical expectations of the ACFs.
